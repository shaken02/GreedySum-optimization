{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda02925-1b45-463a-aba2-cac34808cb42",
   "metadata": {},
   "source": [
    "## All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ada9558-5f38-40d1-a999-414f3c6c2546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T09:05:03.122971Z",
     "iopub.status.busy": "2024-03-22T09:05:03.122744Z",
     "iopub.status.idle": "2024-03-22T09:05:04.588024Z",
     "shell.execute_reply": "2024-03-22T09:05:04.587574Z",
     "shell.execute_reply.started": "2024-03-22T09:05:03.122922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/sh.aubakirov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandoc\n",
    "import pickle \n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7d4a4-c96b-49f6-bde8-2301cdb1bf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T11:23:23.331915Z",
     "iopub.status.busy": "2024-03-19T11:23:23.331342Z",
     "iopub.status.idle": "2024-03-19T11:23:23.334113Z",
     "shell.execute_reply": "2024-03-19T11:23:23.333650Z",
     "shell.execute_reply.started": "2024-03-19T11:23:23.331895Z"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7fce11-4d16-42a1-b976-3c9822de3032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T09:05:11.327219Z",
     "iopub.status.busy": "2024-03-22T09:05:11.326804Z",
     "iopub.status.idle": "2024-03-22T09:05:11.330072Z",
     "shell.execute_reply": "2024-03-22T09:05:11.329536Z",
     "shell.execute_reply.started": "2024-03-22T09:05:11.327198Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_string_to_list(string):  # for dataset of 17038 article texts\n",
    "    try:\n",
    "        return ast.literal_eval(string)\n",
    "    except ValueError:\n",
    "        # In case of error, return the original string\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27ae4f8-e405-419d-a94f-5a1f7d34e1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T09:05:17.918505Z",
     "iopub.status.busy": "2024-03-22T09:05:17.917920Z",
     "iopub.status.idle": "2024-03-22T09:05:35.335847Z",
     "shell.execute_reply": "2024-03-22T09:05:35.335422Z",
     "shell.execute_reply.started": "2024-03-22T09:05:17.918485Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>section_names</th>\n",
       "      <th>sections</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_abstract</th>\n",
       "      <th>sent_ext</th>\n",
       "      <th>word_ext</th>\n",
       "      <th>word_inf</th>\n",
       "      <th>...</th>\n",
       "      <th>len_sum_vot</th>\n",
       "      <th>len_sum_vns_init_greed</th>\n",
       "      <th>best_summary_gen</th>\n",
       "      <th>best_rouge1_gen</th>\n",
       "      <th>best_rouge2_gen</th>\n",
       "      <th>len_sum_gen</th>\n",
       "      <th>best_summary_gen_greedinit</th>\n",
       "      <th>best_rouge1_gen_greedinit</th>\n",
       "      <th>best_rouge2_gen_greedinit</th>\n",
       "      <th>len_sum_gen_greedinit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astro-ph0202198</td>\n",
       "      <td>[the study of supernovae ( sne ) has greatly a...</td>\n",
       "      <td>[large numbers of supernovae ( sne ) have been...</td>\n",
       "      <td>['introduction', 'method', 'results', 'future ...</td>\n",
       "      <td>[['the study of supernovae ( sne ) has greatly...</td>\n",
       "      <td>341</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.076004</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>['once discovered , the study of a particular ...</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.157718</td>\n",
       "      <td>12</td>\n",
       "      <td>['the method presented here can become signifi...</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.153094</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0905.2691</td>\n",
       "      <td>[it is believed that solar magnetic fields are...</td>\n",
       "      <td>[we investigate the emergence of magnetic flux...</td>\n",
       "      <td>['introduction', 'observations and data reduct...</td>\n",
       "      <td>[['it is believed that solar magnetic fields a...</td>\n",
       "      <td>329</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884892</td>\n",
       "      <td>0.073258</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[', the process of flux emergence occurs on ve...</td>\n",
       "      <td>0.598753</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>11</td>\n",
       "      <td>['an important result is that 23% of the loops...</td>\n",
       "      <td>0.598778</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305.7010</td>\n",
       "      <td>[the origin - destination ( od ) matrix is imp...</td>\n",
       "      <td>[the estimation of the number of passengers wi...</td>\n",
       "      <td>['introduction', 'the passenger model', 'the o...</td>\n",
       "      <td>[['the origin - destination ( od ) matrix is i...</td>\n",
       "      <td>225</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.074367</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>['+ the purpose of this paper is then to devel...</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>10</td>\n",
       "      <td>['the ad - hoc estimation is plotted in green ...</td>\n",
       "      <td>0.524109</td>\n",
       "      <td>0.113684</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1402.0371</td>\n",
       "      <td>[multiscale dynamics is present in many phenom...</td>\n",
       "      <td>[the classical structure - function ( sf ) met...</td>\n",
       "      <td>['introduction', 'detrending analysis and detr...</td>\n",
       "      <td>[['multiscale dynamics is present in many phen...</td>\n",
       "      <td>216</td>\n",
       "      <td>15</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.171659</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>['power - law behavior is observed on a large ...</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.354391</td>\n",
       "      <td>15</td>\n",
       "      <td>['this procedure is designated as detrending a...</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>0.487261</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701.00774</td>\n",
       "      <td>[the @xmath3-transformation has been extensive...</td>\n",
       "      <td>[given a real number @xmath0 , we study the as...</td>\n",
       "      <td>['introduction', 'coded negative beta-shift', ...</td>\n",
       "      <td>[['the @xmath3-transformation has been extensi...</td>\n",
       "      <td>353</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>['we understand the closure of the set of expa...</td>\n",
       "      <td>0.599496</td>\n",
       "      <td>0.222785</td>\n",
       "      <td>11</td>\n",
       "      <td>['the previous theorem can be proved also just...</td>\n",
       "      <td>0.560185</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                                       article_text  \\\n",
       "0  astro-ph0202198  [the study of supernovae ( sne ) has greatly a...   \n",
       "1        0905.2691  [it is believed that solar magnetic fields are...   \n",
       "2        1305.7010  [the origin - destination ( od ) matrix is imp...   \n",
       "3        1402.0371  [multiscale dynamics is present in many phenom...   \n",
       "4       1701.00774  [the @xmath3-transformation has been extensive...   \n",
       "\n",
       "                                       abstract_text  \\\n",
       "0  [large numbers of supernovae ( sne ) have been...   \n",
       "1  [we investigate the emergence of magnetic flux...   \n",
       "2  [the estimation of the number of passengers wi...   \n",
       "3  [the classical structure - function ( sf ) met...   \n",
       "4  [given a real number @xmath0 , we study the as...   \n",
       "\n",
       "                                       section_names  \\\n",
       "0  ['introduction', 'method', 'results', 'future ...   \n",
       "1  ['introduction', 'observations and data reduct...   \n",
       "2  ['introduction', 'the passenger model', 'the o...   \n",
       "3  ['introduction', 'detrending analysis and detr...   \n",
       "4  ['introduction', 'coded negative beta-shift', ...   \n",
       "\n",
       "                                            sections  len_text  len_abstract  \\\n",
       "0  [['the study of supernovae ( sne ) has greatly...       341            12   \n",
       "1  [['it is believed that solar magnetic fields a...       329            11   \n",
       "2  [['the origin - destination ( od ) matrix is i...       225            10   \n",
       "3  [['multiscale dynamics is present in many phen...       216            15   \n",
       "4  [['the @xmath3-transformation has been extensi...       353            11   \n",
       "\n",
       "   sent_ext  word_ext  word_inf  ...  len_sum_vot  len_sum_vns_init_greed  \\\n",
       "0  0.000000  0.897436  0.076004  ...           15                       5   \n",
       "1  0.000000  0.884892  0.073258  ...            9                       9   \n",
       "2  0.000000  0.740157  0.074367  ...           19                      14   \n",
       "3  0.066667  0.949045  0.171659  ...           11                      11   \n",
       "4  0.000000  0.867925  0.059547  ...            4                       4   \n",
       "\n",
       "                                    best_summary_gen best_rouge1_gen  \\\n",
       "0  ['once discovered , the study of a particular ...        0.565217   \n",
       "1  [', the process of flux emergence occurs on ve...        0.598753   \n",
       "2  ['+ the purpose of this paper is then to devel...        0.528455   \n",
       "3  ['power - law behavior is observed on a large ...        0.623656   \n",
       "4  ['we understand the closure of the set of expa...        0.599496   \n",
       "\n",
       "   best_rouge2_gen  len_sum_gen  \\\n",
       "0         0.157718           12   \n",
       "1         0.288100           11   \n",
       "2         0.130612           10   \n",
       "3         0.354391           15   \n",
       "4         0.222785           11   \n",
       "\n",
       "                          best_summary_gen_greedinit  \\\n",
       "0  ['the method presented here can become signifi...   \n",
       "1  ['an important result is that 23% of the loops...   \n",
       "2  ['the ad - hoc estimation is plotted in green ...   \n",
       "3  ['this procedure is designated as detrending a...   \n",
       "4  ['the previous theorem can be proved also just...   \n",
       "\n",
       "  best_rouge1_gen_greedinit  best_rouge2_gen_greedinit  len_sum_gen_greedinit  \n",
       "0                  0.568182                   0.153094                     12  \n",
       "1                  0.598778                   0.282209                     11  \n",
       "2                  0.524109                   0.113684                     10  \n",
       "3                  0.736508                   0.487261                     15  \n",
       "4                  0.560185                   0.200000                     11  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('ds_merged_5_methods.csv',sep = ';')\n",
    "dataset['article_text'] = dataset['article_text'].apply(convert_string_to_list)\n",
    "dataset['abstract_text'] = dataset['abstract_text'].apply(convert_string_to_list)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4866965-3681-411d-8f86-f15370e7d382",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.384863Z",
     "iopub.status.idle": "2024-03-22T09:04:50.385016Z",
     "shell.execute_reply": "2024-03-22T09:04:50.384938Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.384930Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['article_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d779474-42bb-4258-92c3-0c6d02534a0c",
   "metadata": {},
   "source": [
    "## Functions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc983aa-6cf3-4081-bb3e-b04e8ae36ea0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.385416Z",
     "iopub.status.idle": "2024-03-22T09:04:50.385562Z",
     "shell.execute_reply": "2024-03-22T09:04:50.385488Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.385480Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower()\n",
    "    \n",
    "def split_into_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def distance_to_line(x0,y0,b,a):\n",
    "    return np.abs(b*x0 - y0 + a)/(np.sqrt(b**2+1))\n",
    "\n",
    "def compute_line_params(x_data, y_data):\n",
    "    m = (y_data[-1] - y_data[0]) / (x_data[-1] - x_data[0])\n",
    "    c = y_data[0] - m * x_data[0]\n",
    "    return m, c\n",
    "\n",
    "def exp_decreasing(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa2b85e-c374-4e1b-8cbe-be9fce47dac4",
   "metadata": {},
   "source": [
    "## Keep the article texts and abstract texts separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c07c5d-9ff5-4641-970e-faf386fd84db",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.386792Z",
     "iopub.status.idle": "2024-03-22T09:04:50.387050Z",
     "shell.execute_reply": "2024-03-22T09:04:50.386938Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.386927Z"
    }
   },
   "outputs": [],
   "source": [
    "article_texts = {}\n",
    "abstract_texts= {}\n",
    "\n",
    "for index, text in dataset['article_text'].items():\n",
    "    paper_id = index\n",
    "    article_texts[paper_id] = text\n",
    "\n",
    "for index,text in dataset['abstract_text'].items():\n",
    "    paper_id = index\n",
    "    abstract_texts[paper_id] = text\n",
    "\n",
    "keys = {key: [] for key in article_texts.keys()}\n",
    "#keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f248ac2-50dd-4d6a-b4ef-a779f55e1d1f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.387540Z",
     "iopub.status.idle": "2024-03-22T09:04:50.387723Z",
     "shell.execute_reply": "2024-03-22T09:04:50.387624Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.387615Z"
    }
   },
   "outputs": [],
   "source": [
    "article_texts[4741]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54509910-212a-4be3-a684-9d8fa7caab9b",
   "metadata": {},
   "source": [
    "#### The function processes a dictionary of article texts, combining text segments per article, splitting them into sentences, and cleaning the text to identify unique words. For each word, it tracks how often it appears across sentences and stores these sentences. The results are aggregated into two dictionaries, one detailing the frequency of each word per article and another mapping words to the sentences they appear in, both keyed by article index. \"Dictionary in Dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227101b-e51a-4f2e-88d8-e6ebe31a6f26",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.388381Z",
     "iopub.status.idle": "2024-03-22T09:04:50.388547Z",
     "shell.execute_reply": "2024-03-22T09:04:50.388464Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.388456Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_sentences_with_unique_words_per_article_fixed(article_texts):\n",
    "    article_word_sentence_counts = {}\n",
    "    article_word_sentence_sets = {}\n",
    "\n",
    "    for index, text_list in article_texts.items():\n",
    "        word_sentence_counts = defaultdict(int) \n",
    "        word_sentence_sets = defaultdict(set)\n",
    "        combined_text = ' '.join(text_list)\n",
    "        sentences = split_into_sentences(combined_text)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            cleaned_sentence = clean_text(sentence)\n",
    "            words = set(cleaned_sentence.split())\n",
    "            for word in words:\n",
    "                if word and word not in {',', '.'}:  \n",
    "                    word_sentence_counts[word] += 1  \n",
    "                    word_sentence_sets[word].add(cleaned_sentence)\n",
    "\n",
    "        article_word_sentence_counts[index] = word_sentence_counts\n",
    "        article_word_sentence_sets[index] = word_sentence_sets\n",
    "    return article_word_sentence_counts,article_word_sentence_sets\n",
    "dict_id_words_counts, dict_id_words_sentences = count_sentences_with_unique_words_per_article_fixed(dataset['article_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24322eb-068d-4241-ac27-4db16874c0c0",
   "metadata": {},
   "source": [
    "### Here we tracked the number of sentences in each article text. At the first time we calculated them by ourselves, then we decided to take already found number of sentences from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597806ee-4078-43fc-a980-81b2ee9fb64a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.389183Z",
     "iopub.status.idle": "2024-03-22T09:04:50.389338Z",
     "shell.execute_reply": "2024-03-22T09:04:50.389259Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.389251Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_sentences_per_article = {}\n",
    "\n",
    "for article_id, word_sentence_sets in dict_id_words_sentences.items():\n",
    "    all_sentences = set()\n",
    "    for sentences in word_sentence_sets.values():\n",
    "        all_sentences.update(sentences)\n",
    "    number_of_sentences_per_article[article_id] = len(all_sentences)\n",
    "\n",
    "number_of_sentences_article_texts_real = dataset['len_text'].to_numpy()\n",
    "number_of_sentences_abstract_texts_real = dataset['len_abstract'].to_numpy()\n",
    "\n",
    "for key,new_value in zip(number_of_sentences_per_article,number_of_sentences_article_texts_real):\n",
    "    number_of_sentences_per_article[key] = new_value\n",
    "\n",
    "#number_of_sentences_per_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09312459-026f-4c85-9d3e-79ebbd0bfe17",
   "metadata": {},
   "source": [
    "### Function that finds optimal min_df values for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a55553-3110-4a47-bf27-17bb4388d9d9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.390021Z",
     "iopub.status.idle": "2024-03-22T09:04:50.390181Z",
     "shell.execute_reply": "2024-03-22T09:04:50.390099Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.390092Z"
    }
   },
   "outputs": [],
   "source": [
    "min_df_values = {key: [] for key in keys.keys()}\n",
    "\n",
    "def find_min_df(key,threshold):\n",
    "    word_count_pairs = [(word, count) for word, count in dict_id_words_counts[key].items()] \n",
    "    filtered_word_count_pairs = [pair for pair in word_count_pairs if pair[1] >= threshold]\n",
    "\n",
    "    sorted_pairs = sorted(filtered_word_count_pairs, key=lambda pair: pair[1], reverse=True)\n",
    "    sorted_words = [pair[0] for pair in sorted_pairs]\n",
    "    sorted_counts = [pair[1] for pair in sorted_pairs]\n",
    "    \n",
    "    words = np.arange(len(sorted_words))\n",
    "    counts = np.array(sorted_counts)\n",
    "\n",
    "    initial_params = [max(counts), 0.1, min(counts)]\n",
    "    params, _ = curve_fit(exp_decreasing, words, counts, p0=initial_params, maxfev=5000)\n",
    "    exp_values = [exp_decreasing(x,*params) for x in words]\n",
    "    m, c = compute_line_params(words, exp_values)\n",
    "    distances_from_exp = [distance_to_line(x, exp_decreasing(x, *params), m, c) for x in words]\n",
    "\n",
    "    intersection_points = []\n",
    "    \n",
    "    for i in range(1,len(exp_values)):\n",
    "        if (exp_values[i-1]-distances_from_exp[i-1]) * (exp_values[i]-distances_from_exp[i]) < 0:\n",
    "            intersection_points.append(i)\n",
    "\n",
    "    try:\n",
    "        min_df = exp_values[intersection_points[1]]/number_of_sentences_per_article[key]\n",
    "    except:\n",
    "        min_df = -1\n",
    "   \n",
    "    return min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ad0ef-912c-4028-896e-e8be256e7b39",
   "metadata": {},
   "source": [
    "### Function that generates summaries for each article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b803e1-a3f5-4db1-a806-df177d3af5f3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.390915Z",
     "iopub.status.idle": "2024-03-22T09:04:50.391081Z",
     "shell.execute_reply": "2024-03-22T09:04:50.390998Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.390990Z"
    }
   },
   "outputs": [],
   "source": [
    "def greed_sum(text, num_sent, min_df, max_df=1.0):\n",
    "    try:\n",
    "        # Fit a TFIDF vectorizer\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
    "        vectorizer.fit(text)\n",
    "\n",
    "        # Get the matrix\n",
    "        X = vectorizer.transform(text).toarray()\n",
    "\n",
    "        # Get the sentence indices\n",
    "        idx = []\n",
    "        while sum(sum(X)) != 0:\n",
    "            ind = np.argmax(X.sum(axis=1))\n",
    "            idx.append(ind)\n",
    "\n",
    "            # Update the matrix by deleting the columns corresponding to the words found in the previous step\n",
    "            cols = X[ind]\n",
    "            col_idx = [i for i in range(len(cols)) if cols[i] > 0]\n",
    "            X = np.delete(X, col_idx, 1)\n",
    "\n",
    "        idx = idx[:num_sent]\n",
    "        idx.sort()\n",
    "\n",
    "        summary = [text[i] for i in idx]\n",
    "        return summary\n",
    "    except ValueError as e:\n",
    "        return [\"Error: \" + str(e)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2f944-c576-4ff5-b4fd-08723d58de11",
   "metadata": {},
   "source": [
    "### Function that compares the generated summary with etalon text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca0e13-fced-46ee-ad27-8ed8540d7eff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.391735Z",
     "iopub.status.idle": "2024-03-22T09:04:50.391898Z",
     "shell.execute_reply": "2024-03-22T09:04:50.391813Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.391806Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_rouge_score(generated_text, etalon_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    generated_text = ' '.join(generated_text)  \n",
    "    etalon_text = ' '.join(etalon_text)  \n",
    "    scores = scorer.score(generated_text, etalon_text)\n",
    "    rouge1_fmeasure = scores['rouge1'].fmeasure  #\n",
    "    return rouge1_fmeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26c0d4-f75e-4275-91e9-0dd6fc5d1806",
   "metadata": {},
   "source": [
    "### The main part of the code. Here we used optimization to find optimal min_df values with all created functions. For each document there is optimal minimum word frequency (threshold), which in turn leads to optimal min_df value such that the highest possible ROUGE score for that document is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba24c28-ab29-4580-ac44-428e354290b5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.392523Z",
     "iopub.status.idle": "2024-03-22T09:04:50.392681Z",
     "shell.execute_reply": "2024-03-22T09:04:50.392601Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.392593Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_thresholds = {}\n",
    "rouge1_fmeasure_scores = {}\n",
    "summary_texts = {}\n",
    "min_df_values_dict = {}\n",
    "for document_id in article_texts.keys():\n",
    "    best_rouge_score = 0\n",
    "    optimal_threshold = None\n",
    "    optimal_generated_text = None\n",
    "    optimal_min_df = None\n",
    "\n",
    "    for threshold in range(0, 20):  \n",
    "        min_df = find_min_df(document_id, threshold)\n",
    "        generated_text = greed_sum(article_texts[document_id], number_of_sentences_per_article[document_id],min_df) \n",
    "        reference_text = abstract_texts[document_id]  \n",
    "        \n",
    "        current_rouge_score = compute_rouge_score(generated_text, reference_text)\n",
    "        if current_rouge_score > best_rouge_score:\n",
    "            best_rouge_score = current_rouge_score\n",
    "            optimal_threshold = threshold\n",
    "            optimal_generated_text = generated_text\n",
    "            optimal_min_df = min_df\n",
    "    rouge1_fmeasure_scores[document_id] = best_rouge_score\n",
    "    min_df_values_dict[document_id] = optimal_min_df\n",
    "    summary_texts[document_id] = optimal_generated_text\n",
    "    \n",
    "    optimal_thresholds[document_id] = optimal_threshold\n",
    "    print(f\"Optimal threshold for document {document_id}: {optimal_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e332dee-e2d2-4034-b86b-fb5601571200",
   "metadata": {},
   "source": [
    "### Example of calculating the ROUGE score for document 4741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f8304-f443-43a7-8d74-3676012ff0b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.393368Z",
     "iopub.status.idle": "2024-03-22T09:04:50.393543Z",
     "shell.execute_reply": "2024-03-22T09:04:50.393455Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.393447Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_texts[4741]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f27acf-2089-436a-aa33-77ee05bfbfbb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.394177Z",
     "iopub.status.idle": "2024-03-22T09:04:50.394339Z",
     "shell.execute_reply": "2024-03-22T09:04:50.394257Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.394249Z"
    }
   },
   "outputs": [],
   "source": [
    "abstract_texts[4741]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51efb6-3cc2-42a3-8af2-e17d1ca05c94",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.394992Z",
     "iopub.status.idle": "2024-03-22T09:04:50.395149Z",
     "shell.execute_reply": "2024-03-22T09:04:50.395070Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.395063Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_rouge_score(summary_texts[4741],abstract_texts[4741])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9edf3-6803-4104-a83f-8f9bda855bf8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.395757Z",
     "iopub.status.idle": "2024-03-22T09:04:50.395912Z",
     "shell.execute_reply": "2024-03-22T09:04:50.395830Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.395822Z"
    }
   },
   "outputs": [],
   "source": [
    "rouge1_fmeasure_scores.values()\n",
    "rouge1_fmeasure_scores = list(rouge1_fmeasure_scores.values())\n",
    "mean_rouge1_fmeasure =np.mean(rouge1_fmeasure_scores)\n",
    "print(mean_rouge1_fmeasure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7b4d1-a195-47e5-a5f8-e7b0785ff502",
   "metadata": {},
   "source": [
    "### Distribution of optimal thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d4e98-8e4b-4db1-bb3b-7467fb08ecd3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.396382Z",
     "iopub.status.idle": "2024-03-22T09:04:50.396543Z",
     "shell.execute_reply": "2024-03-22T09:04:50.396464Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.396456Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_thresholds_list = list(optimal_thresholds.values())\n",
    "max_value = max(optimal_thresholds_list)\n",
    "min_value = min(optimal_thresholds_list)\n",
    "bins = range(min_value, max_value + 2)  # +2 ensures the last bin includes the max value\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(optimal_thresholds_list, bins=bins, align='left', rwidth=0.8)  # align='left' centers the bars over the integers\n",
    "plt.xlabel('Optimal Thresholds')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68875aa3-df57-48ce-9610-cf3901d98365",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.397311Z",
     "iopub.status.idle": "2024-03-22T09:04:50.397465Z",
     "shell.execute_reply": "2024-03-22T09:04:50.397388Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.397380Z"
    }
   },
   "outputs": [],
   "source": [
    "data_series = pd.Series(optimal_thresholds_list)\n",
    "\n",
    "# Create and display the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "data_series.plot(kind='box')\n",
    "plt.title('Boxplot of Data')\n",
    "plt.ylabel('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fd9ea-2b44-4ec4-a814-0ece029e5c25",
   "metadata": {},
   "source": [
    "***Describing relationship between ROUGE scores and min_df values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb136f-c5a0-47e1-aae1-1a1e9093fca6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.398066Z",
     "iopub.status.idle": "2024-03-22T09:04:50.398217Z",
     "shell.execute_reply": "2024-03-22T09:04:50.398140Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.398132Z"
    }
   },
   "outputs": [],
   "source": [
    "min_df_values = []\n",
    "for value in min_df_values_dict.values():\n",
    "    min_df_values.append(value)\n",
    "\n",
    "correlation_coefficient = np.corrcoef(rouge1_fmeasure_scores, min_df_values)[0, 1]\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(min_df_values, rouge1_fmeasure_scores, color='blue', alpha=0.7)\n",
    "plt.title('Scatter Plot of Two Variables')\n",
    "plt.xlabel('Min_df values')\n",
    "plt.ylabel('ROUGE1 F-measure scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e33d67-4b5b-4342-88ec-b8b90e9258ae",
   "metadata": {},
   "source": [
    "**Distribution of ROUGE scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c5b67-1546-4b6f-bae9-dc5285487296",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-22T09:04:50.398829Z",
     "iopub.status.idle": "2024-03-22T09:04:50.398993Z",
     "shell.execute_reply": "2024-03-22T09:04:50.398912Z",
     "shell.execute_reply.started": "2024-03-22T09:04:50.398904Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(rouge1_fmeasure_scores, bins=20, alpha=0.5)\n",
    "plt.xlabel('ROUGE-1 F-measure scores')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(np.mean(rouge1_fmeasure_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shaken)",
   "language": "python",
   "name": "shaken"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
